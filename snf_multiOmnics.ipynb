{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gather": {
     "logged": 1608995475084
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import networkx as nx\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.cluster import SpectralClustering, KMeans\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from myclass.CleanMergeDataset import Clean_Merge_Dataset\n",
    "from myclass.BonferroniTtest import Bonferroni_Ttest\n",
    "#from myclass.SimilarityNetworkFusion import SimilarityNetworkFusion"
   ]
  },
  {
   "source": [
    "# Index\n",
    "* [Load data](#load-data)\n",
    "* [Way to fit the data](#way-to-fit)\n",
    "    * [Standard approach](#standard-approach)\n",
    "    * [Difference between matrices](#difference-matrix)\n",
    "    * [Local minimum approach](#local-minimum)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<a id='load-data'></a>\n",
    "# Load data\n",
    "Loading the datasets, clean them through class *Clean_Merge_Dataset*, reduce the number of features with *Bonferroni_Ttest* and cosider only the cases_id common in the three omnics."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gather": {
     "logged": 1608995811009
    }
   },
   "outputs": [],
   "source": [
    "if os.path.exists('./data-ready/final_dataset_common.json') is False:\n",
    "\n",
    "    data_normal = pd.read_pickle('./data-ready/RNA_dataframe_normal').replace('/', '\\\\')\n",
    "    data_tumor = pd.read_pickle('./data-ready/RNA_dataframe').replace('/', '\\\\')\n",
    "    dataset_RNA, y_RNA, cases_id_RNA = Clean_Merge_Dataset(name='RNA').transform(data_normal, data_tumor)\n",
    "    df_RNA = pd.concat([dataset_RNA, cases_id_RNA], axis=1)\n",
    "\n",
    "    data_normal = pd.read_pickle('./data-ready/miRNA_dataframe_normal').replace('/', '\\\\')\n",
    "    data_tumor = pd.read_pickle('./data-ready/miRNA_dataframe').replace('/', '\\\\')\n",
    "    dataset_miRNA, y_miRNA, cases_id_miRNA= Clean_Merge_Dataset(name='miRNA').transform(data_normal, data_tumor)\n",
    "    df_miRNA = pd.concat([dataset_miRNA, cases_id_miRNA], axis=1)\n",
    "\n",
    "    data_normal = pd.read_pickle('./data-ready/illumina-27-450-normal').replace('/', '\\\\')\n",
    "    data_tumor = pd.read_pickle('./data-ready/illumina450-27-tumor').replace('/', '\\\\')\n",
    "    dataset_illumina, y_illumina, cases_id_illumina= Clean_Merge_Dataset(name='illumina').transform(data_normal, data_tumor)\n",
    "    df_illumina = pd.concat([dataset_illumina, cases_id_illumina], axis=1)\n",
    "\n",
    "    dataset_RNA = Bonferroni_Ttest(label_case_id_into_X=True, alpha=0.05).fit_transform(pd.concat([df_RNA, y_RNA], axis=1), y_RNA)\n",
    "    dataset_miRNA = Bonferroni_Ttest(label_case_id_into_X=True, alpha=0.05).fit_transform(pd.concat([df_miRNA, y_miRNA], axis=1), y_miRNA)\n",
    "    dataset_illumina = Bonferroni_Ttest(label_case_id_into_X=True, alpha=0.05).fit_transform(pd.concat([df_illumina, y_illumina], axis=1), y_illumina)\n",
    "\n",
    "    cases_id = set(dataset_illumina['case_id']) & set(dataset_miRNA['case_id']) & set(dataset_RNA['case_id'])\n",
    "    df_final_illumina = dataset_illumina.loc[dataset_illumina['case_id'].isin(cases_id)]\n",
    "    df_final_rna = dataset_RNA.loc[dataset_RNA['case_id'].isin(cases_id)]\n",
    "    df_final_mirna = dataset_miRNA.loc[dataset_miRNA['case_id'].isin(cases_id)]\n",
    "\n",
    "    df_final_illumina.to_pickle('./data-ready/illumina_pickle.pkl')\n",
    "    df_final_rna.to_pickle('./data-ready/rna_pickle.pkl')\n",
    "    df_final_mirna.to_pickle('./data-ready/miRNA_pickle.pkl')\n",
    "    \n",
    "    my_dict = {\n",
    "        'miRNA': df_final_mirna.to_dict(),\n",
    "        'RNA': df_final_rna.to_dict(),\n",
    "        'illumina': df_final_illumina.to_dict()\n",
    "    }\n",
    "    with open('final_dataset_common.json', 'w') as outfile:\n",
    "        json.dump(my_dict, outfile)\n",
    "    \n",
    "    df_illumina = df_final_illumina.copy()\n",
    "    df_mirna = df_final_mirna.copy()\n",
    "    df_rna = df_final_rna.copy()\n",
    "    \n",
    "    del my_dict\n",
    "    del df_final_illumina\n",
    "    del df_final_rna\n",
    "    del df_final_mirna\n",
    "    del dataset_illumina\n",
    "    del dataset_RNA\n",
    "    del dataset_miRNA\n",
    "else:\n",
    "    df_illumina = pd.read_pickle('./data-ready/illumina_pickle.pkl')\n",
    "    df_mirna = pd.read_pickle('./data-ready/miRNA_pickle.pkl')\n",
    "    df_rna = pd.read_pickle('./data-ready/rna_pickle.pkl')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Illumina's shape (493, 15700)\nmiRNA's shape (473, 237)\nRNA's shape (508, 12965)\n"
     ]
    }
   ],
   "source": [
    "print(\"Illumina's shape {}\".format(df_illumina.shape))\n",
    "print(\"miRNA's shape {}\".format(df_mirna.shape))\n",
    "print(\"RNA's shape {}\".format(df_rna.shape))"
   ]
  },
  {
   "source": [
    "Creating a new features that is composed by the *case_id* plus the *label*, in this way we consider only the case_id with the same label."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_id_new = list()\n",
    "for i, row in df_mirna.iterrows():\n",
    "    case_id_new.append(row['case_id'] + '_' + str(row['label']))\n",
    "df_mirna['case_id_new'] = case_id_new\n",
    "\n",
    "case_id_new = list()\n",
    "for i, row in df_rna.iterrows():\n",
    "    case_id_new.append(row['case_id'] + '_' + str(row['label'])) \n",
    "df_rna['case_id_new'] = case_id_new\n",
    "\n",
    "case_id_new = list()\n",
    "for i, row in df_illumina.iterrows():\n",
    "    case_id_new.append(row['case_id'] + '_' + str(row['label']))\n",
    "df_illumina['case_id_new'] = case_id_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Final illumina's shape (430, 15701)\nFinal miRNA's shape (430, 238)\nFinal RNA's shape (430, 12966)\n"
     ]
    }
   ],
   "source": [
    "cases_id = set(df_mirna['case_id_new']) & set(df_rna['case_id_new']) & set(df_illumina['case_id_new'])\n",
    "df_illumina = df_illumina.loc[df_illumina['case_id_new'].isin(cases_id)]\n",
    "df_rna = df_rna.loc[df_rna['case_id_new'].isin(cases_id)]\n",
    "df_mirna = df_mirna.loc[df_mirna['case_id_new'].isin(cases_id)]\n",
    "\n",
    "print(\"Final illumina's shape {}\".format(df_illumina.shape))\n",
    "print(\"Final miRNA's shape {}\".format(df_mirna.shape))\n",
    "print(\"Final RNA's shape {}\".format(df_rna.shape))"
   ]
  },
  {
   "source": [
    "Drop the case_id because now we consider only the *new* feature composed by case_id with the label."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_illumina.drop(columns=['case_id'], inplace=True, axis=1)\n",
    "df_mirna.drop(columns=['case_id'], inplace=True, axis=1)\n",
    "df_rna.drop(columns=['case_id'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "gather": {
     "logged": 1608997164227
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform, cdist\n",
    "from copy import deepcopy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\"\"\"\n",
    "Similarity Network Fusion:\n",
    "    the parameters used are:\n",
    "        * the datasets: illumina, RNA and miRNA.\n",
    "        * number of iterations: (when we need it).\n",
    "        * number of neighbour: number of case_id to consider close to the case_id considered.\n",
    "        * mu : (μ) is a hyperparameter that can be empirically set. It's recommended to sei between [0.3, 0.8].\n",
    "\n",
    "    N: number of the cases_id.\n",
    "    the algorithm is based on 4 matrices of shape [N x N].\n",
    "        * distances matrix.\n",
    "        * weight matrix.\n",
    "        * P matrix.\n",
    "        * S matrix.\n",
    "\"\"\"\n",
    "\n",
    "class SimilarityNetworkFusion:\n",
    "    def __init__(self, df_mirna, df_rna, df_illumina, k=3, mu=0.3):\n",
    "        \n",
    "        self.cases_id = df_rna.loc[:, 'case_id_new']\n",
    "        self.rna = df_rna.copy()\n",
    "        self.mirna = df_mirna.copy()\n",
    "        self.illumina = df_illumina.copy()\n",
    "        \n",
    "        self.k = k\n",
    "        self.mu = mu\n",
    "        self.check_columns()\n",
    "    \n",
    "    def calculate_matrix(self):\n",
    "        \"\"\"\n",
    "            This is the first method that must be used to calculate the matrices used in the algorithm.\n",
    "        \"\"\"\n",
    "        self.dict_dist = self.calculate_sim_matrix()\n",
    "        if hasattr(self, 'w_rna') is False:\n",
    "            self.w_rna = self.__weights__(self.rna, 'RNA', save_matrix=True)\n",
    "            self.w_mirna = self.__weights__(self.mirna, 'miRNA', save_matrix=True)\n",
    "            self.w_illumina = self.__weights__(self.illumina, 'Illumina', save_matrix=True)\n",
    "        \n",
    "        if hasattr(self, 'p_rna') is False:\n",
    "            self.starting_p_rna = self.P_matrix(self.w_rna.to_numpy().tolist(), self.cases_id.shape[0], 'RNA', save_matrix=True)\n",
    "            self.starting_p_mirna = self.P_matrix(self.w_mirna.to_numpy().tolist(), self.cases_id.shape[0], 'miRNA', save_matrix=True)\n",
    "            self.starting_p_illumina = self.P_matrix(self.w_illumina.to_numpy().tolist(), self.cases_id.shape[0], 'Illumina', save_matrix=True)\n",
    "                \n",
    "        self.s_rna = self.S_matrix(self.w_rna.to_numpy().tolist(), self.cases_id.shape[0], 'RNA')\n",
    "        self.s_mirna = self.S_matrix(self.w_mirna.to_numpy().tolist(), self.cases_id.shape[0], 'miRNA')\n",
    "        self.s_illumina = self.S_matrix(self.w_illumina.to_numpy().tolist(), self.cases_id.shape[0], 'Illumina')\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def calculate_sim_matrix(self):\n",
    "        \"\"\"\n",
    "            The function return the distance between the cases_id.\n",
    "            The matrix is based on the mean of the euclidean distance between the three omnics.\n",
    "        \"\"\"\n",
    "        tot = 0\n",
    "        distance = 'euclidean'\n",
    "        tot += pdist(self.rna, distance)\n",
    "        tot += pdist(self.mirna, distance)\n",
    "        tot += pdist(self.illumina, distance)\n",
    "        tot = tot/3 \n",
    "        df_dist = pd.DataFrame(columns=self.cases_id, index=self.cases_id, data=squareform(tot))\n",
    "        \n",
    "        return df_dist\n",
    "\n",
    "    def __weights__(self, dataset, name, save_matrix=False):\n",
    "        \"\"\"\n",
    "            The function calculates the weight matrix. \n",
    "            We iterates on the cases_id, for each case_id we consider the k neighbours in the distance matrix\n",
    "            and we calculate the weights for patient i and patient j in this way:\n",
    "\n",
    "                W(i, j) = exp( distance(i, j)**2 /(eps * mu))\n",
    "\n",
    "            with:\n",
    "                eps = (topK_mean_i + topK_mean_j + distance(i, j))/3\n",
    "        \"\"\"\n",
    "        if './data-ready/weights_matrix_'+name+'.pkl' in os.listdir('.'):\n",
    "            print('Read file pickle for weights matrix of {}'.format(name))\n",
    "            weights = pd.read_pickle('./data-ready/weights_matrix_'+name+'.pkl')\n",
    "            #dist = pdist(dataset, 'euclidean')\n",
    "            #df_dist = pd.DataFrame(columns=self.cases_id, index=self.cases_id, data=squareform(dist))\n",
    "            #self.dict_dist[name] = df_dist.copy()\n",
    "            return weights\n",
    "        \n",
    "        print('Calculating weights for {}...'.format(name))\n",
    "        df = pd.DataFrame(columns=self.cases_id, data=dataset.T.values)\n",
    "        \n",
    "        #calculate euclidean distance\n",
    "        dist = pdist(dataset, 'euclidean')\n",
    "        df_dist = pd.DataFrame(columns=self.cases_id, index=self.cases_id, data=squareform(dist))\n",
    "        weights = pd.DataFrame(columns=self.cases_id, index=self.cases_id, data=[])\n",
    "                \n",
    "        for i, patient_i in enumerate(tqdm(self.cases_id)):\n",
    "            for patient_j in self.cases_id.iloc[i:]:\n",
    "                    topK_mean_i = np.sort(df_dist.loc[patient_i, :].to_numpy())[:self.k].mean()\n",
    "                    topK_mean_j = np.sort(df_dist.loc[patient_j, :].to_numpy())[:self.k].mean()\n",
    "                    \n",
    "                    eps = (topK_mean_i + topK_mean_j + df_dist.loc[patient_i, patient_j])/3\n",
    "\n",
    "                    weights.loc[patient_i, patient_j] = np.exp(-(df_dist.loc[patient_i, patient_j]**2/(eps*self.mu)))\n",
    "                    weights.loc[patient_j, patient_i] = np.exp(-(df_dist.loc[patient_j, patient_i]**2/(eps*self.mu)))\n",
    "        if save_matrix:\n",
    "            weights.to_pickle('./data-ready/weights_matrix_'+name+'.pkl')\n",
    "        #self.dict_dist[name] = df_dist.copy()\n",
    "        return weights       \n",
    "    \n",
    "    def check_columns(self):\n",
    "        \"\"\"\n",
    "            Check if the dataset contains 'label' or 'case_id_new' features that we don't need.\n",
    "            We use MixMaxScaler to normalize the data for limits of the calculation.\n",
    "\n",
    "            MinMaxScaler: preserves the shape of the original distribution. It doesn’t meaningfully change the information embedded in the original data.\n",
    "                          It doesn’t reduce the importance of outliers.\n",
    "                          The default range for the feature returned by MinMaxScaler is 0 to 1.\n",
    "        \"\"\"\n",
    "        scaler = MinMaxScaler()\n",
    "        if 'label' in self.mirna.columns:\n",
    "            self.mirna.drop(['label'], axis=1, inplace=True)\n",
    "        if 'case_id_new' in self.mirna.columns:\n",
    "            self.mirna.drop(['case_id_new'], axis=1, inplace=True)\n",
    "            \n",
    "        if 'label' in self.rna.columns:\n",
    "            self.rna.drop(['label'], axis=1, inplace=True)\n",
    "        if 'case_id_new' in self.rna.columns:\n",
    "            self.rna.drop(['case_id_new'], axis=1, inplace=True)\n",
    "            \n",
    "        if 'label' in self.illumina.columns:\n",
    "            self.illumina.drop(['label'], axis=1, inplace=True)\n",
    "        if 'case_id_new' in self.illumina.columns:\n",
    "            self.illumina.drop(['case_id_new'], axis=1, inplace=True)\n",
    "            \n",
    "        self.mirna = pd.DataFrame(scaler.fit_transform(self.mirna))\n",
    "        self.rna = pd.DataFrame(scaler.fit_transform(self.rna))\n",
    "        self.illumina = pd.DataFrame(scaler.fit_transform(self.illumina))\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def find_k_neighbors(self, row, i, k=None): \n",
    "        \"\"\"\n",
    "            Find the k neighbours.\n",
    "        \"\"\"\n",
    "        row=deepcopy(row)\n",
    "        #case of P matrix\n",
    "        if k==None:\n",
    "            del row[i]  #delete element of the same column of row index\n",
    "            return row\n",
    "\n",
    "        #case of S (find k elements with minimum distance value of W[i][j])\n",
    "        else:\n",
    "            k_neighbors_index=[]\n",
    "            neigh = 0\n",
    "            max_value = max(row)\n",
    "            for j in range(0, len(row)):\n",
    "                if j!=i:\n",
    "                    min_index = row.index(min(row))\n",
    "                    k_neighbors_index.append(min_index)\n",
    "                    neigh+=1\n",
    "                    row[min_index] = max_value\n",
    "                    if neigh == k:\n",
    "                        return k_neighbors_index\n",
    "\n",
    "\n",
    "    def P_matrix(self, W, n_case_id, name, save_matrix=False):\n",
    "        \"\"\"\n",
    "            P - relative similarity\n",
    "            P carries the full information about the similarity of each patient to all others.\n",
    "            It is calculate in this way:\n",
    "                P(i, j) =  | W(i, j)/(2 *  sum_{k != i}(i, k)) -->  (if i != j)\n",
    "                           | 1/2                               -->  (if i == j)\n",
    "            \n",
    "        \"\"\"\n",
    "        if './data-ready/pStarting_matrix_'+name+'.pkl' in os.listdir('.'):\n",
    "            print('Reading the file pickle for the p starting matrix {}'.format(name))\n",
    "            df_p = pd.read_pickle('./data-ready/pStarting_matrix_'+name+'.pkl')\n",
    "            return df_p.to_numpy()\n",
    "            \n",
    "        print('Calculating P matrix for {}...'.format(name))\n",
    "        P=[]\n",
    "        for i in tqdm(range(0, n_case_id)):\n",
    "            row=[]\n",
    "            for j in range(0,n_case_id):\n",
    "                if i==j:\n",
    "                    row.append(1/2)\n",
    "\n",
    "                else:\n",
    "                    k_neighbors = self.find_k_neighbors(W[i], i)\n",
    "                    denominator = 2*sum(k_neighbors)\n",
    "                    row.append(W[i][j]/denominator)\n",
    "            P.append(row)\n",
    "        #print(np.array(P))\n",
    "        \n",
    "        if save_matrix:\n",
    "            df_P = pd.DataFrame(np.array(P))\n",
    "            df_P.to_pickle('./data-ready/pStarting_matrix_'+name+'.pkl')\n",
    "        return np.array(P)\n",
    "\n",
    "    def S_matrix(self, W, n_case_id, name):\n",
    "        \"\"\"\n",
    "            S - relative similarity within nearest neighbour.\n",
    "            S only encodes the similarity to the K most similar patients for each patient.\n",
    "            It is calculated in this way.\n",
    "                S(i, j) = | W(i, j)/sum_{ k in N} --> if  j in N_i\n",
    "                          | 0                     --> 0 otherwise\n",
    "        \"\"\"\n",
    "        print('Calculating S matrix for {}...'.format(name))\n",
    "        S=[]\n",
    "        for i in tqdm(range(0, n_case_id)):\n",
    "            S_row=[]\n",
    "            neighbors_indeces = self.find_k_neighbors(self.dict_dist.iloc[i,:].to_numpy().tolist(), i, self.k)\n",
    "            for j in range(0,n_case_id):\n",
    "                if j not in neighbors_indeces:\n",
    "                    S_row.append(0)\n",
    "\n",
    "                else:\n",
    "                    np_row = np.array(W[i])\n",
    "                    denominator = sum(np_row[neighbors_indeces])\n",
    "                    S_row.append(W[i][j]/denominator)\n",
    "            S.append(S_row)\n",
    "        #print(np.array(S))\n",
    "        return np.array(S)\n",
    "    \n",
    "    def product_matrix(self, S_matrix, P_matrix):\n",
    "        \"\"\"\n",
    "            Calculate the matrices product:\n",
    "                P_{t+1} = S * P_{t} * S^T\n",
    "        \"\"\"\n",
    "        result = np.dot(S_matrix, P_matrix)\n",
    "        result = np.dot(result, S_matrix.T)\n",
    "        return result\n",
    "    \n",
    "    def sum_matrix_P(self, P1, P2):\n",
    "        \"\"\"\n",
    "            mean between the matrices P1 and P2.\n",
    "        \"\"\"\n",
    "        return np.add(P1,P2)/2\n",
    "    \n",
    "    def fit(self, num_iter=None):\n",
    "        \"\"\"\n",
    "            Execute the number of iteration such that the matrix are update in this way:\n",
    "\n",
    "                1 - P_{t+1}^(1) = S^(1) * P_{t}^(2) * S^{T}^(1) (by product_matrix function)\n",
    "                2 - P_{t+1}^(2) = S^(2) * P_{t}^(1) * S^{T}^(2)\n",
    "\n",
    "            the matrix (2) in the first row and the matrix (1) in the second as the mean between the matrix P of the other 2 omnics.\n",
    "\n",
    "        \"\"\"\n",
    "        if num_iter is not None:\n",
    "            self.p_rna = self.starting_p_rna.copy()\n",
    "            self.p_mirna = self.starting_p_mirna.copy()\n",
    "            self.p_illumina = self.starting_p_illumina.copy()\n",
    "            for i in range(0, num_iter):\n",
    "                self.p_rna_t1 = self.product_matrix(self.s_rna, self.sum_matrix_P(self.p_mirna, self.p_illumina))\n",
    "                self.p_mirna_t1 = self.product_matrix(self.s_mirna, self.sum_matrix_P(self.p_rna, self.p_illumina))\n",
    "                self.p_illumina_t1 = self.product_matrix(self.s_illumina, self.sum_matrix_P(self.p_mirna, self.p_rna))\n",
    "               \n",
    "                self.p_rna = self.p_rna_t1\n",
    "                self.p_mirna = self.p_mirna_t1\n",
    "                self.p_illumina = self.p_illumina_t1\n",
    "\n",
    "        return self\n",
    "    \n",
    "   \n",
    "    def iterations_fit(self, matrices_diff=None, max_iter=100):\n",
    "        \"\"\"\n",
    "            Execute the updating of the matrices in this way:\n",
    "\n",
    "                1 - P_{t+1}^(1) = S^(1) * P_{t}^(2) * S^{T}^(1) (by product_matrix function)\n",
    "                2 - P_{t+1}^(2) = S^(2) * P_{t}^(1) * S^{T}^(2)\n",
    "            \n",
    "            the matrix (2) in the first row and the matrix (1) in the second as the mean between the matrix P of the other 2 omnics.\n",
    "            The function stops when the difference between the P matrices are equal to the parameter matrices_diff passed.\n",
    "            If the differences isn't reached after a num_iteration, it stops automatically.\n",
    "            The difference is calculated as follow:\n",
    "                diff_matrix += | P^(1) - P^(2) |\n",
    "        \"\"\"\n",
    "        if matrices_diff is not None:\n",
    "            self.p_rna = self.starting_p_rna.copy()\n",
    "            self.p_mirna = self.starting_p_mirna.copy()\n",
    "            self.p_illumina = self.starting_p_illumina.copy()\n",
    "            \n",
    "            for step in range(0, max_iter):\n",
    "                self.p_rna_t1 = self.product_matrix(self.s_rna, self.sum_matrix_P(self.p_mirna, self.p_illumina))\n",
    "                self.p_mirna_t1 = self.product_matrix(self.s_mirna, self.sum_matrix_P(self.p_rna, self.p_illumina))\n",
    "                self.p_illumina_t1 = self.product_matrix(self.s_illumina, self.sum_matrix_P(self.p_mirna, self.p_rna))\n",
    "               \n",
    "                self.p_rna = self.p_rna_t1\n",
    "                self.p_mirna = self.p_mirna_t1\n",
    "                self.p_illumina = self.p_illumina_t1\n",
    "\n",
    "                diff_matrix = 0\n",
    "                for i in range(0, len(self.p_rna)):\n",
    "                    for j in range(i, len(self.p_rna)):\n",
    "                        diff_matrix += np.abs(self.p_rna[i][j] - self.p_mirna[i][j])\n",
    "                        diff_matrix += np.abs(self.p_illumina[i][j] - self.p_mirna[i][j])\n",
    "                        diff_matrix += np.abs(self.p_illumina[i][j] - self.p_rna[i][j])\n",
    "                \n",
    "                diff_matrix = diff_matrix**0.5\n",
    "                print(step, ':', diff_matrix)\n",
    "                \n",
    "                #diff_matrix = np.abs(np.subtract(self.p_rna, self.p_mirna)) + np.abs(np.subtract(self.p_rna, self.p_illumina)) + np.abs(np.subtract(self.p_mirna, self.p_illumina))\n",
    "                #diff_matrix= np.abs(np.mean(diff_matrix))\n",
    "                if diff_matrix<=np.abs(matrices_diff):\n",
    "                    print('number of iterations to reach difference: ', step)\n",
    "                    break\n",
    "                    \n",
    "                if step == max_iter-1: ##impossible to reach matrices difference\n",
    "                    print('impossible to reach indicated difference, try with a bigger difference value')\n",
    "        else:\n",
    "            print('no difference for matrices found')\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def local_minimum_fit(self, iters_to_min=None, max_iter=100):\n",
    "        \"\"\"\n",
    "             Execute the updating of the matrices in this way:\n",
    "\n",
    "                1 - P_{t+1}^(1) = S^(1) * P_{t}^(2) * S^{T}^(1) (by product_matrix function)\n",
    "                2 - P_{t+1}^(2) = S^(2) * P_{t}^(1) * S^{T}^(2)\n",
    "            \n",
    "            the matrix (2) in the first row and the matrix (1) in the second as the mean between the matrix P of the other 2 omnics.\n",
    "            The function stops when it reaches the local minum (the lowest value that is repeated for iters_to_min times).\n",
    "            If the differences isn't reached after a num_iteration, it stops automatically.\n",
    "        \"\"\"\n",
    "        if iters_to_min is not None:\n",
    "            self.p_rna = self.starting_p_rna.copy()\n",
    "            self.p_mirna = self.starting_p_mirna.copy()\n",
    "            self.p_illumina = self.starting_p_illumina.copy()\n",
    "            count=0\n",
    "            prev_diff=0\n",
    "            for step in range(0, max_iter):\n",
    "                self.p_rna_t1 = self.product_matrix(self.s_rna, self.sum_matrix_P(self.p_mirna, self.p_illumina))\n",
    "                self.p_mirna_t1 = self.product_matrix(self.s_mirna, self.sum_matrix_P(self.p_rna, self.p_illumina))\n",
    "                self.p_illumina_t1 = self.product_matrix(self.s_illumina, self.sum_matrix_P(self.p_mirna, self.p_rna))\n",
    "               \n",
    "                self.p_rna = self.p_rna_t1\n",
    "                self.p_mirna = self.p_mirna_t1\n",
    "                self.p_illumina = self.p_illumina_t1\n",
    "\n",
    "                diff_matrix = 0\n",
    "                for i in range(0, len(self.p_rna)):\n",
    "                    for j in range(i, len(self.p_rna)):\n",
    "                        diff_matrix += np.abs(self.p_rna[i][j] - self.p_mirna[i][j])\n",
    "                        diff_matrix += np.abs(self.p_illumina[i][j] - self.p_mirna[i][j])\n",
    "                        diff_matrix += np.abs(self.p_illumina[i][j] - self.p_rna[i][j])\n",
    "                \n",
    "                diff_matrix = diff_matrix**0.5\n",
    "                print(step, ':', diff_matrix)\n",
    "                \n",
    "                #diff_matrix = np.abs(np.subtract(self.p_rna, self.p_mirna)) + np.abs(np.subtract(self.p_rna, self.p_illumina)) + np.abs(np.subtract(self.p_mirna, self.p_illumina))\n",
    "                #diff_matrix= np.abs(np.mean(diff_matrix))\n",
    "                \n",
    "                #check if a local minimum is found\n",
    "                if int(diff_matrix)==prev_diff:\n",
    "                    count+=1\n",
    "                    if count>=iters_to_min:\n",
    "                        print('local minimum reached in ', step, 'iterations')\n",
    "                        break\n",
    "                else:\n",
    "                    count=0\n",
    "                    \n",
    "                prev_diff = int(diff_matrix)\n",
    "                    \n",
    "                if step == max_iter-1: ##impossible to reach matrices difference\n",
    "                    print('impossible to reach local minimum, matrices seem to not converge')\n",
    "        else:\n",
    "            print('no minimum iterations for matrices found')\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def clean(self):\n",
    "        \"\"\"\n",
    "            Function to the clean the memory.\n",
    "        \"\"\"\n",
    "        del self.p_rna\n",
    "        del self.p_mirna\n",
    "        del self.p_illumina\n",
    "        \n",
    "        del self.p_rna_t1\n",
    "        del self.p_mirna_t1\n",
    "        del self.p_illumina_t1\n",
    "    \n",
    "        del self.w_rna\n",
    "        del self.w_mirna\n",
    "        del self.w_illumina\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "source": [
    "Before to elaborate the datasets into *SimilarityNetworkFusion* class, we order the datasets by *case_id_new*, this operation helps us with the comparison *case_id - cluster assigned*."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "gather": {
     "logged": 1608998195326
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Calculating weights for RNA...\n",
      "  0%|          | 0/430 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'tokK_mean_j' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-b8ee2af5cafc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_illumina\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'case_id_new'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m sm = SimilarityNetworkFusion(df_mirna,\n\u001b[0m\u001b[1;32m      6\u001b[0m                             \u001b[0mdf_rna\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                             df_illumina, k=100).calculate_matrix()\n",
      "\u001b[0;32m<ipython-input-25-d0bdeb6103ad>\u001b[0m in \u001b[0;36mcalculate_matrix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_sim_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w_rna'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_rna\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__weights__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RNA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_mirna\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__weights__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmirna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'miRNA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_illumina\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__weights__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0millumina\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Illumina'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-d0bdeb6103ad>\u001b[0m in \u001b[0;36m__weights__\u001b[0;34m(self, dataset, name, save_matrix)\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtopK_mean_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpatient_j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                     \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtokK_mean_i\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtokK_mean_j\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpatient_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatient_j\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpatient_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatient_j\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpatient_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatient_j\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokK_mean_j' is not defined"
     ]
    }
   ],
   "source": [
    "df_mirna.sort_values(by='case_id_new', inplace=True)\n",
    "df_rna.sort_values(by='case_id_new', inplace=True)\n",
    "df_illumina.sort_values(by='case_id_new', inplace=True)\n",
    "\n",
    "sm = SimilarityNetworkFusion(df_mirna,\n",
    "                            df_rna,\n",
    "                            df_illumina, k=100).calculate_matrix()"
   ]
  },
  {
   "source": [
    "<a id=\"way-to-fit\"></a>\n",
    "# Way to fit\n",
    "In this section we show differents way that we have developed to fit the matrix\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Standard approach\n",
    "This is the standard approach used in *Similarity Network Fusion* algorithm, where we pass the number of iteration that elaborates.. [to continue]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "gather": {
     "logged": 1608996943544
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SimilarityNetworkFusion at 0x7fb37c81f520>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.fit(num_iter=50)"
   ]
  },
  {
   "source": [
    "<a id=\"difference-matrix\"></a>\n",
    "## Difference between the matrixes\n",
    "continue..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 24.2675195095318\n",
      "1 : 17.570515783431524\n",
      "2 : 14.80683273079802\n",
      "3 : 12.493153185378894\n",
      "4 : 11.074258315168379\n",
      "5 : 9.991503848137087\n",
      "6 : 9.162455005684473\n",
      "7 : 8.496660814992122\n",
      "8 : 7.940946193455418\n",
      "9 : 7.471442703250472\n",
      "10 : 7.064576044267386\n",
      "11 : 6.711158298185656\n",
      "12 : 6.399146930255973\n",
      "13 : 6.12300695737132\n",
      "14 : 5.87649912536672\n",
      "15 : 5.655608169946378\n",
      "16 : 5.457028002568043\n",
      "17 : 5.277464475209049\n",
      "18 : 5.114030904828196\n",
      "19 : 4.964903772046636\n",
      "20 : 4.828368256090836\n",
      "21 : 4.70282571778883\n",
      "22 : 4.58695764399404\n",
      "23 : 4.479673247134771\n",
      "24 : 4.380046991528198\n",
      "25 : 4.287195869935415\n",
      "26 : 4.200543073611898\n",
      "27 : 4.119674048845961\n",
      "28 : 4.044108611443047\n",
      "29 : 3.973136710288096\n",
      "30 : 3.9062743117050673\n",
      "31 : 3.8431890613172137\n",
      "32 : 3.7834511722968065\n",
      "33 : 3.726630731469131\n",
      "34 : 3.6725098691808684\n",
      "35 : 3.620878792832157\n",
      "36 : 3.571529686161098\n",
      "37 : 3.5242787151270294\n",
      "38 : 3.4789086727142555\n",
      "39 : 3.4352768345270377\n",
      "40 : 3.3933481437559823\n",
      "41 : 3.352930012875422\n",
      "42 : 3.3138439294567967\n",
      "43 : 3.276024361344106\n",
      "44 : 3.2393964825744033\n",
      "45 : 3.203877605024217\n",
      "46 : 3.169363492549376\n",
      "47 : 3.1358283943454404\n",
      "48 : 3.1031965896691953\n",
      "49 : 3.0714227534555354\n",
      "50 : 3.0404755281599676\n",
      "51 : 3.010307811380704\n",
      "52 : 2.9808617723155315\n",
      "number of iterations to reach difference:  52\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.SimilarityNetworkFusion at 0x7fb37c81f520>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.iterations_fit(matrices_diff=3)"
   ]
  },
  {
   "source": [
    "<a id=\"local-minimum\"></a>\n",
    "## Local minimum approach\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 24.2675195095318\n",
      "1 : 17.570515783431524\n",
      "2 : 14.80683273079802\n",
      "3 : 12.493153185378894\n",
      "4 : 11.074258315168379\n",
      "5 : 9.991503848137087\n",
      "6 : 9.162455005684473\n",
      "7 : 8.496660814992122\n",
      "8 : 7.940946193455418\n",
      "9 : 7.471442703250472\n",
      "10 : 7.064576044267386\n",
      "11 : 6.711158298185656\n",
      "12 : 6.399146930255973\n",
      "13 : 6.12300695737132\n",
      "14 : 5.87649912536672\n",
      "15 : 5.655608169946378\n",
      "16 : 5.457028002568043\n",
      "17 : 5.277464475209049\n",
      "18 : 5.114030904828196\n",
      "19 : 4.964903772046636\n",
      "20 : 4.828368256090836\n",
      "21 : 4.70282571778883\n",
      "22 : 4.58695764399404\n",
      "23 : 4.479673247134771\n",
      "24 : 4.380046991528198\n",
      "25 : 4.287195869935415\n",
      "26 : 4.200543073611898\n",
      "27 : 4.119674048845961\n",
      "local minimum reached in  27 iterations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.SimilarityNetworkFusion at 0x7fb37c81f520>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.local_minimum_fit(iters_to_min=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "gather": {
     "logged": 1608999830516
    }
   },
   "outputs": [],
   "source": [
    "y_illumina = LabelEncoder().fit_transform(df_illumina.loc[:, 'label'].transform(lambda x: str(x)))\n",
    "y_mirna = LabelEncoder().fit_transform(df_mirna.loc[:, 'label'].transform(lambda x:  str(x)))\n",
    "y_rna = LabelEncoder().fit_transform(df_rna.loc[:, 'label'].transform(lambda x: str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "gather": {
     "logged": 1608999833044
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:72: UserWarning: Array is not symmetric, and will be converted to symmetric by average with its transpose.\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "y_pred = SpectralClustering(n_clusters=3, affinity='precomputed').fit(sm.p_mirna).labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "gather": {
     "logged": 1608999884714
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rand Score:\n",
      "\tIllumina 0.8808569143992506\n",
      "\tMirna 0.8808569143992506\n",
      "\tRNA: 0.8808569143992506\n",
      "\tmean: 0.8808569143992506\n",
      "\n",
      "\n",
      "Silhouette score:\n",
      "\tIllumina 0.20672284127582458\n",
      "\tMirna 0.2103121048452716\n",
      "\tRNA: 0.20672284127369672\n"
     ]
    }
   ],
   "source": [
    "print('Rand Score:')\n",
    "print('\\tIllumina', adjusted_rand_score(y_illumina, y_pred))\n",
    "print('\\tMirna', adjusted_rand_score(y_mirna, y_pred))\n",
    "print('\\tRNA:', adjusted_rand_score(y_rna, y_pred))\n",
    "print('\\tmean:', (adjusted_rand_score(y_rna, y_pred) + adjusted_rand_score(y_illumina, y_pred) + adjusted_rand_score(y_mirna, y_pred))/3)\n",
    "\n",
    "print('\\n')\n",
    "print('Silhouette score:')\n",
    "print('\\tIllumina', silhouette_score(sm.p_illumina, y_pred))\n",
    "print('\\tMirna', silhouette_score(sm.p_mirna, y_pred))\n",
    "print('\\tRNA:', silhouette_score(sm.p_rna, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = KMeans(n_clusters=3).fit(sm.p_mirna).labels_\n",
    "print('Rand Score:')\n",
    "print('\\tIllumina', adjusted_rand_score(y_illumina, y_pred))\n",
    "print('\\tMirna', adjusted_rand_score(y_mirna, y_pred))\n",
    "print('\\tRNA:', adjusted_rand_score(y_rna, y_pred))\n",
    "print('\\n')\n",
    "print('Silhouette score:')\n",
    "print('\\tIllumina', silhouette_score(sm.p_illumina, y_pred))\n",
    "print('\\tMirna', silhouette_score(sm.p_mirna, y_pred))\n",
    "print('\\tRNA:', silhouette_score(sm.p_rna, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####SI POTREBBE UTILIZZARE COME CONDIZIONE DI TERMINAZIONE CON UN CERTO VALORE\n",
    "diff_matrix = np.abs(np.subtract(sm.p_rna, sm.p_mirna), sm.p_illumina)\n",
    "print(np.mean(diff_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prove con geni di ATLAS**\n",
    "da aggiungere il controllo su case_id_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normal = pd.read_pickle('./data-ready/RNA_dataframe_normal').replace('/', '\\\\')\n",
    "data_tumor = pd.read_pickle('./data-ready/RNA_dataframe').replace('/', '\\\\')\n",
    "dataset_RNA, y_RNA, cases_id_RNA = Clean_Merge_Dataset(name='RNA').transform(data_normal, data_tumor)\n",
    "dataset_RNA = pd.concat([dataset_RNA, cases_id_RNA, y_RNA], axis=1)\n",
    "\n",
    "data_normal = pd.read_pickle('./data-ready/miRNA_dataframe_normal').replace('/', '\\\\')\n",
    "data_tumor = pd.read_pickle('./data-ready/miRNA_dataframe').replace('/', '\\\\')\n",
    "dataset_miRNA, y_miRNA, cases_id_miRNA= Clean_Merge_Dataset(name='miRNA').transform(data_normal, data_tumor)\n",
    "df_miRNA = pd.concat([dataset_miRNA, cases_id_miRNA], axis=1)\n",
    "\n",
    "data_normal = pd.read_pickle('./data-ready/illumina-27-450-normal').replace('/', '\\\\')\n",
    "data_tumor = pd.read_pickle('./data-ready/illumina450-27-tumor').replace('/', '\\\\')\n",
    "dataset_illumina, y_illumina, cases_id_illumina= Clean_Merge_Dataset(name='illumina').transform(data_normal, data_tumor)\n",
    "df_illumina = pd.concat([dataset_illumina, cases_id_illumina], axis=1)\n",
    "\n",
    "dataset_miRNA = Bonferroni_Ttest(label_case_id_into_X=True, alpha=0.05).fit_transform(pd.concat([df_miRNA, y_miRNA], axis=1), y_miRNA)\n",
    "dataset_illumina = Bonferroni_Ttest(label_case_id_into_X=True, alpha=0.05).fit_transform(pd.concat([df_illumina, y_illumina], axis=1), y_illumina)\n",
    "\n",
    "cases_id = set(dataset_illumina['case_id']) & set(dataset_miRNA['case_id']) & set(dataset_RNA['case_id'])\n",
    "df_final_illumina = dataset_illumina.loc[dataset_illumina['case_id'].isin(cases_id)]\n",
    "df_final_rna = dataset_RNA.loc[dataset_RNA['case_id'].isin(cases_id)]\n",
    "df_final_mirna = dataset_miRNA.loc[dataset_miRNA['case_id'].isin(cases_id)]\n",
    "\n",
    "print(df_final_illumina.shape)\n",
    "print(df_final_rna.shape)\n",
    "print(df_final_mirna.shape)\n",
    "\n",
    "df_illumina = df_final_illumina.copy()\n",
    "df_mirna = df_final_mirna.copy()\n",
    "df_rna = df_final_rna.copy()\n",
    "\n",
    "with open('all_ensgs_no_version.json') as f:\n",
    "    genes = json.load(f)\n",
    "print('Number of genes available:', len(genes))\n",
    "print('Starting shape RNA:',df_rna.shape)\n",
    "columns = [col.split('.')[0] for col in df_rna.columns]\n",
    "columns = [original for gene, original in zip(columns, df_rna.columns) if gene in genes]\n",
    "columns.append('case_id')\n",
    "columns.append('label')\n",
    "df_rna = df_rna.loc[:, columns]\n",
    "print('Final shape RNA:', df_rna.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mirna.sort_values(by='case_id', inplace=True)\n",
    "df_rna.sort_values(by='case_id', inplace=True)\n",
    "df_illumina.sort_values(by='case_id', inplace=True)\n",
    "\n",
    "sm = SimilarityNetworkFusion(df_mirna.drop_duplicates(subset='case_id'),\n",
    "                            df_rna.drop_duplicates(subset='case_id'),\n",
    "                            df_illumina.drop_duplicates(subset='case_id'), k=100).calculate_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.local_minimum_fit(iters_to_min=8)\n",
    "#sm.iterations_fit(matrices_diff=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_illumina = LabelEncoder().fit_transform(df_illumina.drop_duplicates(subset='case_id').loc[:, 'label'].transform(lambda x: str(x)))\n",
    "y_mirna = LabelEncoder().fit_transform(df_mirna.drop_duplicates(subset='case_id').loc[:, 'label'].transform(lambda x:  str(x)))\n",
    "y_rna = LabelEncoder().fit_transform(df_rna.drop_duplicates(subset='case_id').loc[:, 'label'].transform(lambda x: str(x)))\n",
    "\n",
    "y_pred = SpectralClustering(n_clusters=3, affinity='precomputed').fit(sm.p_mirna).labels_\n",
    "\n",
    "print('Rand Score:')\n",
    "print('\\tIllumina', adjusted_rand_score(y_illumina, y_pred))\n",
    "print('\\tMirna', adjusted_rand_score(y_mirna, y_pred))\n",
    "print('\\tRNA:', adjusted_rand_score(y_rna, y_pred))\n",
    "print('\\tmean:', (adjusted_rand_score(y_rna, y_pred) + adjusted_rand_score(y_illumina, y_pred) + adjusted_rand_score(y_mirna, y_pred))/3)\n",
    "\n",
    "print('\\n')\n",
    "print('Silhouette score:')\n",
    "print('\\tIllumina', silhouette_score(sm.p_illumina, y_pred))\n",
    "print('\\tMirna', silhouette_score(sm.p_mirna, y_pred))\n",
    "print('\\tRNA:', silhouette_score(sm.p_rna, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}